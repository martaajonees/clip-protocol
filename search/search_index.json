{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Homepage","text":""},{"location":"#welcome-to-clip-protocol","title":"Welcome to CLiP Protocol","text":"<p>The CLiP protocol (context-aware Local Information Protection Protocol) is a novel solution for frequency estimation with personalized privacy budgets.</p> <p>It empowers individual data owners \u2014 such as students \u2014 to protect their personal data while still enabling meaningful learning analytics.</p> <p>Unlike traditional Local Differential Privacy (LDP) approaches, which assign a uniform privacy budget to all users, the CLiP Protocol introduces a personalized privacy-by-design approach. This ensures that individual characteristics and privacy preferences are respected without sacrificing the utility of the collected data.</p>"},{"location":"#why-clip-protocol","title":"\u2728 Why CLiP Protocol?","text":"<p>In conventional LDP implementations, data collectors define a general privacy budget for all participants, regardless of personal sensitivity or data variability. This \"one-size-fits-all\" model is insufficient when users have diverse privacy needs.</p> <p>CLiP Protocol solves this by: - Allowing each individual to select their privacy level. - Preserving critical data utility for learning analytics. - Supporting privacy without relying on trusted servers.</p>"},{"location":"#how-it-works","title":"\ud83d\udee0\ufe0f How It Works","text":"<p>The CLiP Protocol relies on privacy sketching and LDP techniques for sequential data events like: - Student activity logs - Click counts - Interaction events</p> <p>The process is divided into two main components:</p> Client Side Server Side Runs on the data owner's device Runs on the data collector\u2019s server Preprocesses and privatizes data Aggregates privatized data and handles queries Applies the privacy mechanism locally Updates frequency sketches and responds to frequency queries <p>The server is treated as untrusted: it only receives already privatized data.</p>"},{"location":"#main-actors","title":"\ud83d\udc65 Main Actors","text":"<ul> <li> <p>Data Owner: An individual providing raw information (e.g., students, researchers).</p> </li> <li> <p>Data Collector: Institutions like universities managing the privatized data.</p> </li> <li> <p>Data Consumer: External researchers or parties requesting frequency-based insights.</p> </li> </ul>"},{"location":"#workflow-stages","title":"\ud83e\udde9 Workflow Stages","text":"<p>The CLiP Protocol operates through four functional stages:</p> <ol> <li> <p>Setup: Configuration of privacy parameters prior to data collection.</p> </li> <li> <p>Mask: Client-side anonymization of raw data based on personalized privacy budgets.</p> </li> <li> <p>Aggregation: Server-side update of frequency sketches with privatized input.</p> </li> <li> <p>Estimation: Server-side frequency estimation and response to queries.</p> </li> </ol> <p>Only the Mask stage occurs on the client side, ensuring that raw data never leaves the owner\u2019s device unprotected.</p> <p> </p> <p>The figure above illustrates the complete CLiP Protocol workflow, showing how privacy and utility are balanced across client and server components.</p>"},{"location":"api-reference/","title":"API Reference","text":""},{"location":"api-reference/#setup","title":"setup","text":"<p><pre><code>class Setup:\n    def __init__(self, df)\n</code></pre> Initializes the Setup instance.</p> <p>Parameters:</p> <ul> <li><code>df</code> (pd.DataFrame). The test dataset</li> </ul> <p><pre><code>def ask_values(self)\n</code></pre> Prompts the user to input configuration parameters.</p> <p>Returns:</p> <ul> <li><code>events_names</code> (list): Name of the columns in the dataset to be filtered. Two columns must be selected<ul> <li>One that contains the users name (later on they will be pseudonymize)</li> <li>One that contains the event information we want to do estimations</li> </ul> </li> <li><code>privacy_method</code> (str): Name of the privacy method that will be used to privatized the dataset (Only can be PCMeS or PHCMS)</li> <li><code>error_metric</code> (str): Name of the metric we wil use to calculate the error (Only can be MSE, Lp Norm or RMSE)</li> <li><code>error_value</code> (float): Value of the maximun error we want our data to have (in decimal). For example, if we want a 2% maximun error, 0.02 must be written.</li> <li><code>tolerance</code> (float): Value of the tolerance of the error it is needed.</li> </ul> <p><pre><code>def filter_dataframe(self)\n</code></pre> Filters the input DataFrame based on the selected event columns.</p> <p>Returns: - <code>pd.DataFrame</code>: The filtered DataFrame.</p> <p><pre><code>def run_command(self, e, k, m)\n</code></pre> Executes the selected privacy-preserving algorithm with the given parameters.</p> <p>Parameters:</p> <ul> <li><code>e</code>(float): Privacy budget (epsilon).</li> <li><code>k</code> (int): Number of hash functions.</li> <li><code>m</code> (int): Number of buckets.</li> </ul> <p>Returns:  - <code>error_table</code> (table). Table of all the parameters of error - <code>df_estimated</code> (table). Table with the estimated frecuency of the events.</p> <p><pre><code>def optimize_k_m(self, er=150)\n</code></pre> Optimizes the parameters k and m using Optuna.</p> <p>Parameters:</p> <ul> <li><code>er</code> (float, optional): Initial reference value for epsilon. Default is 150.</li> </ul> <p>Returns: - <code>er</code>(float): Privacy budget (epsilon) of reference for the next stage. - <code>k</code> (int): Number of hash functions. - <code>m</code> (int): Number of buckets.</p> <p><pre><code>def minimize_epsilon(self, k, m)\n</code></pre> Minimizes the privacy budget (<code>epsilon</code>) while satisfying the defined error constraint.</p> <p>Parameters:</p> <ul> <li><code>k</code> (int): Number of hash functions.</li> <li><code>m</code> (int): Number of buckets.</li> </ul> <p>Returns:</p> <ul> <li><code>e</code> (int): Optimal epsilon value.</li> </ul>"},{"location":"api-reference/#mask","title":"mask","text":"<p><pre><code>class Mask:\n    def __init__(self, privacy_level, df):\n</code></pre> Initializes the Mask instance by loading configuration parameters.</p> <p>Parameters:</p> <ul> <li><code>privacy_level</code> (str): Privacy level identifier.</li> <li><code>df</code> (pd.DataFrame): The input dataset.</li> </ul> <p><pre><code>def filter_dataframe(self)\n</code></pre> Filters the input DataFrame based on previously selected event columns and pseudonymizes the user identifiers. Returns:</p> <ul> <li><code>pd.DataFrame</code>: The filtered and pseudonymized DataFrame.</li> </ul> <p><pre><code>def calculate_metrics(self, f_estimated, f_real)\n</code></pre> Calculates the evaluation metrics between estimated and real frequencies. Parameters:</p> <ul> <li><code>f_estimated</code> (pd.DataFrame): Estimated frequency distribution.</li> <li><code>f_real</code> (pd.DataFrame): Real frequency distribution.</li> </ul> <p>Returns:</p> <ul> <li>Placeholder for metric value calculation.</li> </ul> <p><pre><code>def pseudonimize(self, user_name)\n</code></pre> Takes a user's name as input and returns a pseudonymized version by hashing the name using the SHA-256 algorithm and truncating it to the first 10 characters.</p> <p>Input:</p> <ul> <li>User's name (<code>user_name</code>).</li> </ul> <p>Output:</p> <ul> <li>A 10-character pseudonymized hash of the user's name.</li> </ul> <p><pre><code> def optimize_e(self)\n</code></pre> Optimizes the privacy parameter \u03f5 using Optuna to minimize the error between real and estimated frequencies while ensuring the selected privacy level is met. It returns the best \u03f5 value that achieves the desired privacy error threshold. Input</p> <ul> <li>None (uses class attributes like <code>privacy_level</code>, <code>error_value</code>, and <code>tolerance</code>).</li> </ul> <p>Output:</p> <ul> <li>The best optimized \u03f5, privatized data, and associated coefficients.</li> </ul>"},{"location":"api-reference/#aggregate","title":"aggregate","text":"<p><pre><code>def update_sketch_matrix(M, k, e, privacy_method, data_point)\n</code></pre> Updates the sketch matrix based on the privatized data using either the \"PCMeS\" or \"PHCMS\" privacy method. It processes the given data point and modifies the matrix accordingly.</p> <p>Input:</p> <ul> <li><code>M</code>: The sketch matrix.</li> <li><code>k</code>: Parameter used in matrix updates.</li> <li><code>e</code>: Privacy parameter.</li> <li><code>privacy_method</code>: The privacy method to apply (\"PCMeS\" or \"PHCMS\").</li> <li><code>data_point</code>: Data point used to update the matrix (could be vector, index, or weight).</li> </ul> <p>Output:</p> <ul> <li>The updated sketch matrix (<code>M</code>).</li> </ul> <p><pre><code>class Agregate:\n    def __init__(self):\n</code></pre> This is the constructor for the Agregate class. It loads the necessary privacy parameters and dataset for aggregation, initializing an empty dictionary to store user-specific sketches.</p> <p>Output: </p> <ul> <li>Initializes the Agregate instance with privacy settings and an empty dictionary for user sketches.</li> </ul> <p><pre><code>def compute_data(self, user_data):\n</code></pre> Computes a sketch matrix for a given user's data. It iterates over the user data and updates the sketch matrix using the specified privacy method. The progress of the operation is displayed.</p> <p>Input: </p> <ul> <li><code>user_data</code>: Data related to a specific user.</li> </ul> <p>Output: </p> <ul> <li>A tuple with the user's ID and the computed sketch matrix (<code>M</code>) along with the number of data points (<code>N</code>).</li> </ul> <p><pre><code>def agregate_per_user(self)\n</code></pre> Aggregates sketches for all users in the dataset by processing their data with the compute_data function. It stores the resulting sketches in a dictionary.</p> <p>Output: </p> <ul> <li>A dictionary (<code>sketch_by_user</code>) mapping user IDs to their computed sketches.</li> </ul>"},{"location":"api-reference/#estimate","title":"estimate","text":"<p><pre><code>class Estimation:\n    def __init__(self):\n</code></pre> Constructor for the Estimation class. It loads the necessary aggregated data (<code>sketch_by_user</code>) and privacy settings (<code>k</code>, <code>m</code>, <code>epsilon</code>, <code>hashes</code>, <code>method</code>) from JSON files to initialize the estimation process.</p> <p>Output: </p> <ul> <li>Initializes the Estimation instance with user sketches and privacy settings.</li> </ul> <p><pre><code>def estimate_element(self, d, M, N)\n</code></pre> Estimates the frequency of an element d in the dataset using the sketch matrix <code>M</code> and the number of data points <code>N</code>. The estimation is based on a formula involving the privacy settings.</p> <p>Input:</p> <ul> <li><code>d</code>: The element whose frequency is to be estimated.</li> <li><code>M</code>: The sketch matrix for a user.</li> <li><code>N</code>: The number of data points for the user.</li> </ul> <p>Output:  - The estimated frequency of the element <code>d</code> for the user.</p> <p><pre><code>def query_all_users_event(self, event):\n</code></pre> Estimates the frequency of an event for each user in the dataset. It prints the estimated frequency for each user by calling the <code>estimate_element</code> method.</p> <p>Input: </p> <ul> <li><code>event</code>: The event (element) whose frequency needs to be estimated.</li> </ul> <p>Output: </p> <ul> <li>Prints the estimated frequency of the event for each user.</li> </ul> <p><pre><code>def run_estimate()\n</code></pre> Initializes the Estimation instance and prompts the user to input an event. It continuously estimates the frequency of the event for all users until the user decides to quit by entering \"q\".</p>"},{"location":"api-reference/#utils","title":"utils","text":"<p><pre><code>def save_setup_json(setup_instance)\n</code></pre> Saves the initial setup configuration to a JSON file (<code>setup_config.json</code>), including parameters like <code>k</code>, <code>m</code>, <code>epsilon</code>, event names, privacy method, error metrics, tolerance, and p.</p> <p>Input:</p> <ul> <li><code>setup_instance</code>: Object containing the setup parameters.</li> </ul> <p>Output: JSON configuration file saved.</p> <p><pre><code>def load_setup_json()\n</code></pre> Loads the setup configuration from the previously saved JSON file.</p> <p>Output: Tuple with <code>k</code>, <code>m</code>, <code>epsilon</code>, <code>events_names</code>, <code>privacy_method</code>, <code>error_metric</code>, <code>error_value</code>, <code>tolerance</code> and <code>p</code>.</p> <p><pre><code>def save_mask_json(mask_instance, e, coeffs, privatized_dataset)\n</code></pre> Saves the mask configuration and the privatized dataset to disk (<code>mask_config.json</code> and <code>privatized_dataset.csv</code>).</p> <p>Input:</p> <ul> <li><code>mask_instance</code>: Mask configuration instance.</li> <li><code>e</code>: Epsilon value.</li> <li><code>coeffs</code>: Hash function coefficients.</li> <li><code>privatized_dataset</code>: Privatized dataset.</li> </ul> <p>Output: JSON and CSV files saved.</p> <pre><code>def load_mask_json()\n</code></pre> <p>Loads the mask configuration, rebuilds the hash functions, and loads the privatized dataset.</p> <p>Output: Tuple with<code>k</code>, <code>m</code>, <code>e</code>, rebuilt hash functions, <code>privacy_method</code>, and the dataset as a DataFrame.</p> <p><pre><code>def save_agregate_json(agregate_instance)\n</code></pre> Saves the user sketch aggregation object to a binary file (sketch_by_user).</p> <p>Input:</p> <ul> <li><code>agregate_instance</code>: Instance containing the user sketches.</li> </ul> <p><pre><code>def load_agregate_json()\n</code></pre> Loads the user sketch aggregation object from the binary file.</p> <p>Output: Loaded sketch_by_user object.</p> <p><pre><code>def deterministic_hash(x)\n</code></pre> Generates a deterministic hash of an element using SHA-256, returning it as an integer.</p> <p>Input:</p> <ul> <li><code>x</code>: Element to be hashed.</li> </ul> <p>Output: Deterministic hash as an integer.</p> <p><pre><code>def generate_hash_functions(k, p, c, m)\n</code></pre> Generates <code>k</code> hash functions based on random coefficients over a finite field defined by <code>p</code>, mapped to <code>m</code>.</p> <p>Input:</p> <ul> <li> <p><code>k</code>: Number of hash functions.</p> </li> <li> <p><code>p</code>: Large prime number for modular operations.</p> </li> <li> <p><code>c</code>: Polynomial degree.</p> </li> <li> <p><code>m</code>: Output range.</p> </li> </ul> <p>Output:</p> <ul> <li>List of hash functions.</li> <li>Dictionary with function parameters.</li> </ul> <p><pre><code>def rebuild_hash_functions(functions_params)\n</code></pre> Rebuilds hash functions from their stored coefficients and parameters.</p> <p>Input:</p> <ul> <li><code>functions_params</code>: Dictionary with <code>coefficients</code>, <code>p</code>, <code>m</code>, and <code>c</code>.</li> </ul> <p>Output:</p> <ul> <li>List of rebuilt hash functions.</li> </ul> <p><pre><code>def display_results(real_freq: pd.DataFrame, estimated_freq: dict)\n</code></pre> Displays real vs estimated frequencies of elements, including absolute differences and percentage errors.</p> <p>Input:</p> <ul> <li> <p><code>real_freq</code>: DataFrame with real frequencies.</p> </li> <li> <p><code>estimated_freq</code>: Dictionary with estimated frequencies.</p> </li> </ul> <p>Output:</p> <ul> <li>List of tabulated results with real count, real percentage, estimated count, estimated percentage, difference, and percent error.</li> </ul> <p><pre><code>def get_real_frequency(df)\n</code></pre> Computes the real frequency of each element in a DataFrame.</p> <p>Input:</p> <ul> <li><code>df</code>: DataFrame containing a value column.</li> </ul> <p>Output:</p> <ul> <li>DataFrame with columns Element and Frequency.</li> </ul>"},{"location":"api-reference/#notes","title":"\ud83d\udcce Notes","text":"<ul> <li> <p>Make sure that your input file does not have incorrectly named columns (e.g., <code>Unnamed: 0</code>).</p> </li> <li> <p>Pseudonymization is applied using simple hashing.</p> </li> </ul>"},{"location":"installation/","title":"Instalation","text":"<p>Setting up the CLiP Protocol on your device is simple and quick!</p>"},{"location":"installation/#install-via-pypi","title":"\ud83d\udce6 Install via PyPI","text":"<p>Run the following command to install: <pre><code>pip install clip-protocol\n</code></pre></p> <p>\ud83d\udcce Note: You can also view the package on PyPI.</p>"},{"location":"installation/#usage","title":"\u2699\ufe0f Usage","text":"<p>Once installed, you can execute the following commands to run the privacy adjustment methods:</p>"},{"location":"installation/#setup","title":"Setup","text":"<p>Prepares your dataset for the CLiP workflow. This step formats and validates your input data for the next phases.</p> <pre><code>setup -d &lt;dataset&gt;\n</code></pre> <ul> <li><code>&lt;dataset&gt;</code>: Path to the input dataset in <code>.xlsx</code> format.</li> </ul>"},{"location":"installation/#mask","title":"Mask","text":"<p>Applies personalized local differential privacy to your dataset. This command privatizes the data based on individual privacy budgets.</p> <pre><code>mask -d &lt;dataset&gt; -o &lt;output&gt;\n</code></pre> <ul> <li><code>&lt;dataset&gt;</code>: Path to the input dataset you want to privatize.</li> <li><code>output</code>: Path to where the privatized dataset will be saved.</li> </ul> <p>\ud83d\udcce Note: After masking, a new <code>.csv</code> file will be created containing the privatized data.</p> <p>The <code>output</code> variable is optional, if it is not needed to save the privatized data you can skip it</p>"},{"location":"installation/#aggregation","title":"Aggregation","text":"<p>Combines the privatized data points into frequency sketches. This command updates the server-side structures needed for final analysis. <pre><code>agregate\n</code></pre> This command updates the frequency sketches based on the privatized inputs.</p>"},{"location":"installation/#estimation","title":"Estimation","text":"<p>Estimates the true frequencies from the aggregated privatized data. This command answers frequency queries based on the collected sketches. <pre><code>estimate\n</code></pre></p>"},{"location":"installation/#clear","title":"Clear","text":"<p>Use this command when it is needed to delete all data saved from the previous steps. <pre><code>clip_clear\n</code></pre></p>"},{"location":"installation/#important-notes","title":"Important Notes","text":"<ul> <li> <p>\u2705 Ensure that dataset paths are correct and accessible.</p> </li> <li> <p>\ud83d\udee1\ufe0f Make sure you have permission to read/write at the specified locations.</p> </li> <li> <p>\ud83d\udcc4 The mask step will output a .csv file containing the privatized version of your dataset.</p> </li> </ul>"}]}